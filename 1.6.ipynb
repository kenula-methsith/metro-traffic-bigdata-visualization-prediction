{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a0cf35-0447-47d8-b6b4-32e5ae57afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+-------------------+\n",
      "|             Mean|            StdDev|            Skewness|           Kurtosis|\n",
      "+-----------------+------------------+--------------------+-------------------+\n",
      "|3259.618133521489|1986.9544648251451|-0.08905846571674847|-1.3091559302917255|\n",
      "+-----------------+------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean, stddev, skewness, kurtosis\n",
    "\n",
    "# Step 1: Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Summary Statistics for Traffic Volume\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path =  r'C:\\Users\\thinu\\Desktop\\KENULA\\top-up\\data\\cleaned_transformed_dataset2.csv'\n",
    "\n",
    "# Ensure the file exists and is accessible\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Create 'reduced_df' with non-null 'traffic_volume'\n",
    "reduced_df = data.select(\"traffic_volume\").filter(data[\"traffic_volume\"].isNotNull())\n",
    "\n",
    "# Step 4: Compute summary statistics\n",
    "summary_df = reduced_df.select(\n",
    "    mean(\"traffic_volume\").alias(\"Mean\"),\n",
    "    stddev(\"traffic_volume\").alias(\"StdDev\"),\n",
    "    skewness(\"traffic_volume\").alias(\"Skewness\"),\n",
    "    kurtosis(\"traffic_volume\").alias(\"Kurtosis\")\n",
    ")\n",
    "\n",
    "# Step 5: Show the results\n",
    "summary_df.show()\n",
    "\n",
    "# Step 6: Stop Spark Session\n",
    "spark.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34de534-9e89-4bb2-90c9-57ea4cd1b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-------------------+-----------------+\n",
      "|             Mean|           StdDev|           Skewness|         Kurtosis|\n",
      "+-----------------+-----------------+-------------------+-----------------+\n",
      "|281.2049945005903|13.33873796577709|-2.2474097668758093|39.91830115843366|\n",
      "+-----------------+-----------------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean, stddev, skewness, kurtosis\n",
    "\n",
    "# Step 1: Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Summary Statistics for temp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path =  r'C:\\Users\\thinu\\Desktop\\KENULA\\top-up\\data\\cleaned_transformed_dataset2.csv'\n",
    "\n",
    "# Ensure the file exists and is accessible\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Create 'reduced_df' with non-null 'traffic_volume'\n",
    "reduced_df = data.select(\"temp\").filter(data[\"temp\"].isNotNull())\n",
    "\n",
    "# Step 4: Compute summary statistics\n",
    "summary_df = reduced_df.select(\n",
    "    mean(\"temp\").alias(\"Mean\"),\n",
    "    stddev(\"temp\").alias(\"StdDev\"),\n",
    "    skewness(\"temp\").alias(\"Skewness\"),\n",
    "    kurtosis(\"temp\").alias(\"Kurtosis\")\n",
    ")\n",
    "\n",
    "# Step 5: Show the results\n",
    "summary_df.show()\n",
    "\n",
    "# Step 6: Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be666fb1-1362-4d9b-a28e-30671afbabf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------------+-----------------+\n",
      "|                Mean|             StdDev|          Skewness|         Kurtosis|\n",
      "+--------------------+-------------------+------------------+-----------------+\n",
      "|2.224666403801857...|0.00816905077483839|48.357440005447636|2619.268300755711|\n",
      "+--------------------+-------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean, stddev, skewness, kurtosis\n",
    "\n",
    "# Step 1: Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Summary Statistics for snow_1h\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path =  r'C:\\Users\\thinu\\Desktop\\KENULA\\top-up\\data\\cleaned_transformed_dataset2.csv'\n",
    "\n",
    "# Ensure the file exists and is accessible\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Create 'reduced_df' with non-null 'traffic_volume'\n",
    "reduced_df = data.select(\"snow_1h\").filter(data[\"snow_1h\"].isNotNull())\n",
    "\n",
    "# Step 4: Compute summary statistics\n",
    "summary_df = reduced_df.select(\n",
    "    mean(\"snow_1h\").alias(\"Mean\"),\n",
    "    stddev(\"snow_1h\").alias(\"StdDev\"),\n",
    "    skewness(\"snow_1h\").alias(\"Skewness\"),\n",
    "    kurtosis(\"snow_1h\").alias(\"Kurtosis\")\n",
    ")\n",
    "\n",
    "# Step 5: Show the results\n",
    "summary_df.show()\n",
    "\n",
    "# Step 6: Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8709ee-2715-41b0-9ec5-b1d4b7383f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+------------------+-----------------+\n",
      "|              Mean|           StdDev|          Skewness|         Kurtosis|\n",
      "+------------------+-----------------+------------------+-----------------+\n",
      "|0.3343818872309983|44.79703269348369|219.34351945262026|48133.64919028338|\n",
      "+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean, stddev, skewness, kurtosis\n",
    "\n",
    "# Step 1: Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Summary Statistics for rain_1h\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path =  r'C:\\Users\\thinu\\Desktop\\KENULA\\top-up\\data\\cleaned_transformed_dataset2.csv'\n",
    "\n",
    "# Ensure the file exists and is accessible\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Create 'reduced_df' with non-null 'traffic_volume'\n",
    "reduced_df = data.select(\"rain_1h\").filter(data[\"rain_1h\"].isNotNull())\n",
    "\n",
    "# Step 4: Compute summary statistics\n",
    "summary_df = reduced_df.select(\n",
    "    mean(\"rain_1h\").alias(\"Mean\"),\n",
    "    stddev(\"rain_1h\").alias(\"StdDev\"),\n",
    "    skewness(\"rain_1h\").alias(\"Skewness\"),\n",
    "    kurtosis(\"rain_1h\").alias(\"Kurtosis\")\n",
    ")\n",
    "\n",
    "# Step 5: Show the results\n",
    "summary_df.show()\n",
    "\n",
    "# Step 6: Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f1e541-e2b6-46c4-89ca-da93ddccb9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+-------------------+\n",
      "|             Mean|            StdDev|            Skewness|           Kurtosis|\n",
      "+-----------------+------------------+--------------------+-------------------+\n",
      "|49.36545126278872|39.015212752422116|-0.19738024536278448|-1.7421532908058215|\n",
      "+-----------------+------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean, stddev, skewness, kurtosis\n",
    "\n",
    "# Step 1: Start Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Summary Statistics for clouds_all\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "file_path =  r'C:\\Users\\thinu\\Desktop\\KENULA\\top-up\\data\\cleaned_transformed_dataset2.csv'\n",
    "\n",
    "# Ensure the file exists and is accessible\n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Step 3: Create 'reduced_df' with non-null 'traffic_volume'\n",
    "reduced_df = data.select(\"clouds_all\").filter(data[\"clouds_all\"].isNotNull())\n",
    "\n",
    "# Step 4: Compute summary statistics\n",
    "summary_df = reduced_df.select(\n",
    "    mean(\"clouds_all\").alias(\"Mean\"),\n",
    "    stddev(\"clouds_all\").alias(\"StdDev\"),\n",
    "    skewness(\"clouds_all\").alias(\"Skewness\"),\n",
    "    kurtosis(\"clouds_all\").alias(\"Kurtosis\")\n",
    ")\n",
    "\n",
    "# Step 5: Show the results\n",
    "summary_df.show()\n",
    "\n",
    "# Step 6: Stop Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82d3bd-ffcc-4c00-b33b-948285273077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
