{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf8101a-be3b-48c0-b913-a21a8b90b31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Attribute Data Type  Unique Values  Missing Values  \\\n",
      "0              holiday    object             11           48143   \n",
      "1                 temp   float64           5843               0   \n",
      "2              rain_1h   float64            372               0   \n",
      "3              snow_1h   float64             12               0   \n",
      "4           clouds_all     int64             60               0   \n",
      "5         weather_main    object             11               0   \n",
      "6  weather_description    object             38               0   \n",
      "7            date_time    object          40575               0   \n",
      "8       traffic_volume     int64           6704               0   \n",
      "\n",
      "                                       Sample Values  \n",
      "0  [nan, Columbus Day, Veterans Day, Thanksgiving...  \n",
      "1           [288.28, 289.36, 289.58, 290.13, 291.14]  \n",
      "2                       [0.0, 0.25, 0.57, 0.38, 0.3]  \n",
      "3                      [0.0, 0.51, 0.32, 0.06, 0.05]  \n",
      "4                                [40, 75, 90, 1, 20]  \n",
      "5               [Clouds, Clear, Rain, Drizzle, Mist]  \n",
      "6  [scattered clouds, broken clouds, overcast clo...  \n",
      "7  [10/2/2012 9:00, 10/2/2012 10:00, 10/2/2012 11...  \n",
      "8                     [5545, 4516, 4767, 5026, 4918]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(r'C:\\Users\\thinu\\Desktop\\KENULA\\top-up\\data\\Metro_Interstate_Traffic_Volume.csv')\n",
    "\n",
    "# Generate meta-data table\n",
    "meta_data = []\n",
    "\n",
    "for column in df.columns:\n",
    "    data_type = df[column].dtype  # Data type of the column\n",
    "    unique_values = df[column].nunique()  # Count of unique values\n",
    "    missing_values = df[column].isnull().sum()  # Count of missing values\n",
    "    sample_values = df[column].unique()[:5]  # First 5 unique values as a sample\n",
    "\n",
    "    meta_data.append({\n",
    "        \"Attribute\": column,\n",
    "        \"Data Type\": data_type,\n",
    "        \"Unique Values\": unique_values,\n",
    "        \"Missing Values\": missing_values,\n",
    "        \"Sample Values\": sample_values\n",
    "    })\n",
    "\n",
    "# Convert the meta-data into a DataFrame\n",
    "meta_data_df = pd.DataFrame(meta_data)\n",
    "\n",
    "# Display the meta-data table\n",
    "print(meta_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6b282-ab40-446f-acce-27f4e54d7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
